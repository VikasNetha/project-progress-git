{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMPORT NECESSARY LIBRARIES</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import matplotlib as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SOURCES FOR DATASET</H1>\n",
    "<h3>https://www.kaggle.com/datasets/akshat103/e-waste-image-dataset</h3>\n",
    "<h3>https://www.kaggle.com/datasets/mostafaabla/garbage-classification</h3>\n",
    "<h3>https://www.kaggle.com/datasets/vencerlanz09/plastic-paper-garbage-bag-synthetic-images</h3>\n",
    "The dataset used for this project is a collection from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_labels = {\n",
    "    0: 'Biological',\n",
    "    1: 'Cardboard',\n",
    "    2: 'Clothes',\n",
    "    3: 'E-waste',\n",
    "    4: 'Glass',\n",
    "    5: 'Metal',\n",
    "    6: 'Paper',\n",
    "    7: 'Plastic',\n",
    "    8: 'Shoes'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>UPDATE THE PARAMETERS AS REQUIRED</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 9  # Update this to match the number of classes in your dataset\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>class_distribution_of_dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory containing your dataset\n",
    "dataset_dir = r\"directory_of_dataset\"\n",
    "\n",
    "# Get the class names (subdirectories in the dataset directory)\n",
    "class_names = os.listdir(dataset_dir)\n",
    "\n",
    "# Count the number of items in each class\n",
    "class_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    num_items = len(os.listdir(class_dir))\n",
    "    class_counts[class_name] = num_items\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Items')\n",
    "plt.title('Number of Items in Each Class')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"E:\\DATASETS\"\n",
    "validation_dir = r\"E:\\validation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>imageprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Create the validation generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the class indices\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"Class indices:\", class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>cnn model architechrure</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>model training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional epochs to train\n",
    "additional_epochs = 30\n",
    "\n",
    "# Continue training for additional epochs\n",
    "history_additional = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=additional_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE)\n",
    "\n",
    "# Save the model in HDF5 format to the desktop directory\n",
    "model.save(r'enter_the_path_to_save_the_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>for predecting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(r\"C:\\Users\\vikas\\Desktop\\garbage_model_test.keras\")\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (150, 150)\n",
    "\n",
    "# Define the image path\n",
    "image_path = r\"C:\\Users\\vikas\\Downloads\\garbage_classification\\plastic\\plastic765.jpg\" # Replace 'path_to_your_test_image.jpg' with the actual path to your test image\n",
    "\n",
    "# Define class labels mapping\n",
    "class_labels = {\n",
    "    0: 'Biological',\n",
    "    1: 'Cardboard',\n",
    "    2: 'Clothes',\n",
    "    3: 'E-waste',\n",
    "    4: 'Glass',\n",
    "    5: 'Metal',\n",
    "    6: 'Paper',\n",
    "    7: 'Plastic',\n",
    "    8: 'Shoes'\n",
    "}\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=IMAGE_SIZE)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Normalize the image data to [0, 1]\n",
    "\n",
    "# Predict the class probabilities for the image\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get the corresponding class label\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "# Print the predicted class label\n",
    "print(\"Predicted class:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy'] # store training accuracy in history\n",
    "val_acc = history.history['val_accuracy'] # store validation accuracy in history\n",
    "train_loss = history.history['loss'] # store training loss in history\n",
    "val_loss = history.history['val_loss'] # store validation loss in history\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc, 'g*-', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'g*-', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Predict classes for the dataset\n",
    "y_pred = model.predict(X_dataset)  # Assuming X_dataset contains your image data\n",
    "\n",
    "# Step 2: Calculate accuracy for each class\n",
    "class_accuracies = []\n",
    "for class_label in range(num_classes):\n",
    "    # Filter predictions and ground truth for the current class\n",
    "    y_true_class = y_dataset[y_dataset == class_label]\n",
    "    y_pred_class = y_pred[y_dataset == class_label]\n",
    "    \n",
    "    # Calculate accuracy for the current class\n",
    "    class_accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "    class_accuracies.append(class_accuracy)\n",
    "\n",
    "# Step 3: Print accuracy for each class\n",
    "for class_label, accuracy in enumerate(class_accuracies):\n",
    "    print(f\"Class {class_label}: Accuracy = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "plt.bar(range(num_classes), class_accuracies)\n",
    "plt.title('Class-wise Accuracy')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(num_classes))  # Set x-axis ticks to class indices\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
